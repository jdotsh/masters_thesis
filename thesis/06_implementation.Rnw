\chapter{Implementation of the $k$-LSM Priority Queue} \label{ch:implementation}

\begin{comment}
* Initially: language and libraries used, cmake, interfaces, general guidelines
  (modularity, template use for flexible key/value types & relaxation), header programming.
  Mention tests, benching utilities (bench.py, plot.R, unpheet.sh, etc). rationale
  - why is a standalone impl needed -> measurability, composability missing in original,
  etc.
  
* top down: klsm interface, members, methods. 
  slsm interface, members, methods. dlsm interface, members, methods.
  further components.
  
* lock-free memory management. martin's item mm. block mm (2 methods), block
  array pool. instances where we need to take special care of reuse (e.g.
  when merging & size of blocks exceeds capacity (?)).
  
* important steps in development. performance jumps (-flto, binary search pivots,
  pointer walks). find more and show benchmarks.
\end{comment}

Contrary to the previous chapter in which the concept of the \klsm was briefly
described, this chapter will cover the implementation details of the new standalone
\klsm.

But first, a rationale --- why is a standalone \klsm implementation desirable?
There are several reasons:

\begin{itemize}
\item Comparability. The original \klsm implementation within the task-scheduling
      framework Pheet \cite{wimmer2013data,wimmer2015lock} 
      (simply referred to as the \emph{Pheet \klsm} within this
      thesis) has been demonstrated to perform very well; but how well exactly
      when compared to other state of the art queues is not easy to determine
      since the Pheet \klsm implementation is tied tightly to the Pheet framework.
      A standalone \klsm will allow other for easy comparability against other
      queues and answer how its performance compares to the state of the art.
\item Use in practice. A standalone \klsm can easily be integrated into applications
      for use in practice.
\item Maintainability. The Pheet \klsm implementation is focused on maximal performance
      and makes tradeoffs that pose challenges to maintainability. While the standalone
      \klsm also aims to achieve high performance, the reimplementation also 
      explicitly values classical software engineering concepts such as 
      composability, readability, and separation of concerns.
\item Further insight and improvements. Finally, a reimplementation by a fresh
      set of eyes can create new insight into the design and might result in
      improvements to further increase performance over the original Pheet \klsm.
\end{itemize}

The standalone \klsm (referred to as the \emph{klsm} in the remaining chapter)
is implemented in C++11 using a minimal set of dependencies on other libraries.
The included benchmark application requires the \emph{hwloc} library for hardware-independent
thread pinning, while other priority queues included for benchmarking purposes
require the \ac{GSL}. The raw \klsm implementation itself has no external 
dependencies.

Full code for the \klsm implementation is available at 
\url{https://github.com/schuay/kpqueue}. The directory structure is as follows:
\lstinline|doc/| contains autogenerated documentation in the Doxygen\footnote{\url{http://www.stack.nl/~dimitri/doxygen/}} format, \lstinline|lib/| contains external source code for other priority queues used
for benchmarking, \lstinline|misc/| contains various utility scripts which handle
conversion of raw benchmarking output from various formats into plots using R\footnote{\url{https://www.r-project.org/}}, \lstinline|src/| contains code for the standalone \klsm and various benchmarking
tools, and \lstinline|test/| contains the test suite.

The following sections describe the \klsm implementation in top-down order ---
Section \ref{sec:klsm_internals} begins with the \klsm itself, Sections \ref{sec:slsm_internals}
and \ref{sec:dlsm_internals} descend to the component queues \ac{SLSM} and \ac{DLSM},
while several other components are covered in Section \ref{sec:component_internals}.
The various applied methods of lock-free memory management are covered in Section \ref{sec:mm_internals};
and finally, aspects of the implementation which have proven especially relevant
for performance are highlighted in Section \ref{sec:implementation_impact}.

\section{\klsm Internals} \label{sec:klsm_internals}

While the general \klsm interface has been covered previously in Section \ref{sec:wimmer},
several details have been omitted for clarity. Figure \ref{fig:klsm.h} displays the full
header file containing the \lstinline|k_lsm| class. In this instance, implementation
details such constructors and destructors, as the \lstinline|init_thread| function,
are included in order to present a complete picture of what a class implementation
looks like. Future code listings will skip these details.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V, int Rlx>
class k_lsm {
public:
    k_lsm();
    virtual ~k_lsm() { }

    void insert(const K &key);
    void insert(const K &key,
                const V &val);

    bool delete_min(V &val);

    void init_thread(const size_t) const { }
    constexpr static bool supports_concurrency() { return true; }

private:
    dist_lsm<K, V, Rlx>   m_dist;
    shared_lsm<K, V, Rlx> m_shared;
};

#include "k_lsm_inl.h"
\end{lstlisting}
\caption{The \klsm header.}
\label{fig:klsm.h}
\end{figure}

The \lstinline|k_lsm| class is a template class parameterized by \lstinline|K|
and \lstinline|V|, respectively the key- and value types, as well as the relaxation
parameter \lstinline|Rlx|, which corresponds to the $k$ in \klsm. Code for template class
must be exclusively located in header files, but it is possibly to preserve readability
using a pattern of inlined headers: the main header includes a class declaration,
while an inline header contains the class definition and is itself 
included in the standard header. The \lstinline|init_thread| function is provided
for queues which require per-thread initialization.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V, int Rlx>
void
k_lsm<K, V, Rlx>::insert(const K &key,
                         const V &val)
{
    m_dist.insert(key, val, &m_shared);
}
\end{lstlisting}
\caption{The \lstinline|k_lsm::insert| implementation.}
\label{fig:k_lsm::insert}
\end{figure}

Trivialities aside, implementation of the \lstinline|k_lsm| class is extremely simple since it relies
on a composition of the \ac{SLSM} and \ac{DLSM} queues. Insertion (see Figure \ref{fig:k_lsm::insert})
simply triggers insertion into the local \ac{DLSM}, passing a pointer to the global
\ac{SLSM} queue in case the maximal size of local blocks is exceeded.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V, int Rlx>
bool
k_lsm<K, V, Rlx>::delete_min(V &val)
{
    typename block<K, V>::peek_t
            best_dist = block<K, V>::peek_t::EMPTY(),
            best_shared = block<K, V>::peek_t::EMPTY();

    do {
        m_dist.find_min(best_dist);
        m_shared.find_min(best_shared);

        if (!best_dist.empty() && !best_shared.empty()) {
            if (best_dist.m_key < best_shared.m_key) {
                return best_dist.take(val);
            } else {
                return best_shared.take(val);
            }
        }

        if (!best_dist.empty() /* and best_shared is empty */) {
            return best_dist.take(val);
        }

        if (!best_shared.empty() /* and best_dist is empty */) {
            return best_shared.take(val);
        }
    } while (m_dist.spy() > 0);

    return false;
}
\end{lstlisting}
\caption{The \lstinline|k_lsm::delete_min| implementation.}
\label{fig:k_lsm::delete_min}
\end{figure}

Deletions (Figure \ref{fig:k_lsm::delete_min}) call \lstinline|find_min| 
on both the \ac{SLSM} and \ac{DLSM} queues
and return the lesser of both items in the standard case. In case both queues
are empty, the local \ac{DLSM} attempts to copy items from another thread by
triggering a call to \lstinline|spy|, and finally retrying deletion.

These implementations seem simple, even basic; but that is because details are
delegated to responsible classes. The best example in this case is the act of
item removal --- how can we ensure that an item is taken only a single thread? 
And since memory for items is reused (see Section \ref{sec:mm_internals}),
how can we prevent the ABA problem in which memory is reused after being
retrieved (i.e. the thread reads data different than had been intended)?

The answer lies within the \lstinline|peek_t| class, which contains both
a pointer to the item and an associated expected item version. Within \lstinline|peek_t::take|,
a \ac{CAS} instruction is used to atomically increment the item's version, if,
and only if it previously matched the given expected version. In the presence
of two identical \ac{CAS} calls by different threads, only one will succeed
while the other must fail. The thread which has seen a \ac{CAS} failure will
return from from \lstinline|delete_min| with a so-called spurious failure,
returning \lstinline|false| even though the queue might be non-empty.

\section{\acl{SLSM} Internals} \label{sec:slsm_internals} 
\section{\acl{DLSM} Internals} \label{sec:dlsm_internals}
\section{Component Internals} \label{sec:component_internals}

\section{Memory Management} \label{sec:mm_internals}
\subsection{Items} \label{ssec:item_mm_internals}
\subsection{Blocks} \label{ssec:block_mm_internals}
\subsection{Block Arrays} \label{ssec:block_array_mm_internals}

\section{Implementation Impact on Performance} \label{sec:implementation_impact}