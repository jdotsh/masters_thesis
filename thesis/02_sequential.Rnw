\chapter{Sequential Priority Queues} \label{ch:sequential}

\begin{comment}
* What is a priority queue? Exact semantics.
* Brief overview of important sequential pqs - check books and surveys.
* More detailed explanation of relevant queue types: heaps, possibly binary
  trees & skiplists.
\end{comment}

Priority queues have a long history, having been extensively studied since the early
days of the field of computer science. Some of the oldest designs, such as the
heap, have remained popular in practical use up today. This chapter will
detail syntax and semantics of general shared memory priority queues,
and provide an overview of important sequential priority queue types,
going into further detail for those designs which are also relevant for
use in a concurrent environment.

\section{Syntax and Semantics}

Before going further, we define syntax and semantics for strict, sequential
priority queues as used in this thesis.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V>
class priority_queue {
public:
    void insert(const K &key, const V &val);
    bool delete_min(V &val);
};
\end{lstlisting}
\caption{A generic priority queue class.}
\label{fig:priority_queue_interface}
\end{figure}

% TODO: Interface of delete_min: why is the key not returned? Discussion of other
% interface styles (boost, LEDA, stl) - they all do pop/top/insert.

A priority queue is a data structure which holds a collection of key-value
pairs, and provides two methods (see Figure \ref{fig:priority_queue_interface}):
\lstinline|insert|, which takes a key
and a value argument, possibly of different types, and inserts them into the queue;
and \lstinline|delete_min|,
which writes the value of the least item within the queue into the given parameter,
and returns true if the operation succeeded. \lstinline|delete_min| may fail if,
for instance, the priority queue is empty.

There are various further possible extensions to the given interface:
\begin{itemize}
\item \lstinline|empty| states whether the queue is empty.
\item \lstinline|peek_min| returns the minimal item's value without removing
      it from the queue.
\item \lstinline|decrease_key| decreases the key of a given item. This operation
      is vital e.g. for an efficient implementation of Dijkstra's shortest
      paths algorithm\cite{dijkstra1959note}.
\item \lstinline|meld| merges two priority queues.
\end{itemize}
However, these are outside the scope of this thesis.

Each priority queue is associated with a priority function, which maps
the key domain $K$ to a priority domain $P$, over which there exists
a reflective, antisymmetric, and transitive ordering relation $\leq: P \times P$.

When $K$ and $P$ are the set of integers $\mathbb{Z}$, a priority queue is termed a
``max-priority queue'' if the priority function is the identity function $f(x) = x$,
i.e., if higher keys have higher priority.
It is called a ``min-priority queue'' if the priority function is the additive
inverse $f(x) = -x$.

We are interested mainly in general priority queues within the context of shared
memory systems. General priority queues are data structures which
allow arbitrary keys of a given, possibly infinite set, and furthermore can
hold multiple distinct items with identical keys. Such priority queues
are congruent the sorting problem\cite{Thorup:2002:EPQ:645413.652157},
and thus have a lower bound of $O(\log n)$
complexity for either \lstinline|insert| or \lstinline|delete_min| (or both).
Note that these bounds do not
hold for more specialized priority queues; for instance, queues which are limited
to a small, previously known set of keys may use a bucket for each key and
implement both insertions and deletions in constant time.

The semantics of general sequential priority priority queues are as follows:
\begin{itemize}
\item The contents of a priority queue $PQ$ are a set of key-value pairs called items:
      $PQ \subseteq K \times V$, where $K$ and $V$ are, respectively, the key
      and value domains.
\item Upon creation, at time $t = 0$, a priority queue is empty:
      $PQ_{t = 0} = \emptyset$.
\item Let $PQ^+_t$ be the set of all key-value pairs inserted into the priority
      queue up to time $t$, and let $PQ^-_t$ be the set of all items
      removed up to time $t$. At each instant in time $t$, the set of items
      within the priority queue is then $PQ_t = PQ^+_t \setminus PQ^-_t$.
\item An insertion of key $k$ and value $v$ simply adds the pair to the set of
      inserted items.
\item A deletion at time $t$ finds the item $(k, v) \in PQ_t$ such that
      $\forall (x, y) \in PQ_t: f(x) \leq f(k)$ according to the priority function defined
      above.
      If such an item does not exist, i.e. the queue is empty, false is returned.
      Otherwise, $(k, v)$ is added to the set of deleted items, and $(\text{true}, v)$
      is returned to the caller.
\end{itemize}
Note that we do not define an order within items of identical keys, and thus the
priority queue is allowed to choose freely among items of equal priority.

In the following, we assume a min-priority queue and do not distinguish precisely
between keys and their associated priority function. For instance, we simply
use ``the minimal item'' to refer to the item within the queue of highest priority.

\section{Overview}

A naive implementation of a priority queue could be realized by using an cyclical array
sorted according to the priority function. Access to the minimal element is
possible in constant time since it is located at the head of the array. However,
insertions need to insert the new item into its correct position within the
array, and move all larger items back by one position, resulting in a worst-case
complexity of $\Theta(n)$.

More efficient implementation techniques have been known for over half a century.
Binary heaps \cite{williams1964algorithm} were invented as part of the sorting
algorithm Heapsort in \citedate{williams1964algorithm} and are still arguable the most
popular design for general purpose priority queues. For example, the priority queue
container class contained in the C++ \ac{STL} implements a binary heap on top of
any compatible backing structure. When using a heap, both deletions and insertions require
reorganization of the data structure and have logarithmic
worst-case complexity.

While heaps use an implicit tree structure, it is also possible to use explicit
balanced \acp{BST} as priority queues with identical worst case bounds as heaps.
Popular \ac{BST} variants are e.g. Red-black trees \cite{bayer1972symmetric} and
AVL trees \cite{adelsonvelskii1963algorithm}.
Insertions use the standard \ac{BST} insert algorithm, while deletions remove
the tree's leftmost item. Alternatively, SkipLists \cite{pugh1990skip} also
provide logarithmic complexity but do not require periodic maintenance operations
since they rely on randomization to preserve a balanced data structure.

Fibonacci heaps \cite{fredman1987fibonacci} were invented by
\citeauthor{fredman1987fibonacci} and are based on a collection of
heap-sorted trees. In addition to the standard insertion and deletion operations
(in amortized logarithmic time),
they also support efficient \lstinline|merge| and \lstinline|decrease_key|
operations in amortized constant time, thus decreasing the complexity of Dijkstra's shortest
path algorithm to $O(|E| + |V| \log |V|)$. However, due to their programming complexity
and involved constant factors, they are not commonly used in practise.
Subsequent publications have proposed various alternatives to Fibonacci heaps
such as relaxed heaps \cite{driscoll1988relaxed} and strict Fibonacci heaps
\cite{brodal2012strict}.

Other well-known priority queue designs are the Skew Heap \cite{sleator1986self}
based on a heap-ordered binary tree and the \lstinline|meld| operation;
the Splay Tree \cite{sleator1985self}, a heuristically balanced \ac{BST}
which attempts to move frequently used sections towards the root of the tree;
pairing heaps \cite{fredman1986pairing}, a self-adjusting version of the
binomial heap \cite{vuillemin1978data}; and many more. For further
information, we refer the reader to reviews such as
\cite{ronngren1997comparative,jones1986empirical}.

% TODO: Possibly extend this section, more detail.

\section{Binary Heaps}

Binary heaps  \cite{williams1964algorithm} are one of the most common (and also one of the simplest)
methods of implementing priority queues. They are based on two concepts; first,
that of complete balanced binary trees, composed of nodes with exactly two children each.
And second, that of heap ordering, the notion that the priority of each child
node is less or equal to that of its parent node. Furthermore, instead of using an
explicit representation of a binary tree, heaps implicitly encode the position
of their contents in a so-called heap-ordered array.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V>
class heap {
public:
    void insert(const K &key, const V &val);
    bool delete_min(V &val);

private:
    std::pair<K, V> items[CAPACITY];
    size_t n;
};
\end{lstlisting}
\caption{A binary heap class.}
\label{fig:heap_members}
\end{figure}

As shown in Figures \ref{fig:heap_members} and \ref{fig:heap_structure},
the backing data structure of a binary heap is a flat array of \lstinline|items| together
with a variable \lstinline|n| tracking the number of items within the heap. The root item,
i.e. the item with the highest priority, is located at the head of the array
\lstinline|items[1]|\footnote{For ease
of presentation, we use 1-based indexing within this section.}. For each item
at position \lstinline|items[i]|, its left child is located at \lstinline|items[2i]| and its right child
at \lstinline|items[2i + 1]|. Vice versa, the parent item of position \lstinline|items[i]| can be found
at \lstinline|items[i / 2]|.

\begin{figure}
\begin{minipage}[b]{.5\textwidth}
\centering
\begin{tikzpicture}[every node/.style = box]
\node (1) at (0, 0)    {$0$};
\node (2) at (5mm, 0)  {$2$};
\node (3) at (10mm, 0) {$1$};
\node (4) at (15mm, 0) {$4$};
\node (5) at (20mm, 0) {$6$};
\node (6) at (25mm, 0) {$5$};
\node (7) at (30mm, 0) {$3$};
\node (8) at (35mm, 0) {$7$};
\node (9) at (40mm, 0) {$8$};

\path[->, every node/.style= { font = \sffamily\small }]
(1) edge[bend right = 60] node [right] {} (2)
(1) edge[bend right = 60] node [right] {} (3)
(2) edge[bend left = 60] node [right] {} (4)
(2) edge[bend left = 60] node [right] {} (5)
(3) edge[bend right = 60] node [right] {} (6)
(3) edge[bend right = 60] node [right] {} (7)
(4) edge[bend left = 60] node [right] {} (8)
(4) edge[bend left = 60] node [right] {} (9);
\end{tikzpicture}
\subcaption{Array representation. Arrows show the implicit parent-child connections
between items.}
\end{minipage}%
\begin{minipage}[b]{.5\textwidth}
\centering
\begin{tikzpicture}[
    ->,
    every node/.style = box,
    level distance = 10mm,
    level 1/.style = { sibling distance = 20mm },
    level 2/.style = { sibling distance = 10mm }]]
  \node {$0$}
    child { node {$2$}
      child { node {$4$}
        child { node {$7$} }
        child { node {$8$} } }
      child { node {$6$} } }
    child { node {$1$}
      child { node {$5$} }
      child { node {$3$} } };
\end{tikzpicture}
\subcaption{Tree representation.}
\end{minipage}
\caption[A binary heap structured as an array, and as a tree.]
        {The same heap displayed once in its native array representation,
         and once as its corresponding tree.}
\label{fig:heap_structure}
\end{figure}

Insertions initially append the new item at the tail of array \lstinline|items[n + 1]|.
Note that heap order might be violated at this point if the inserted item has a
higher priority than its parent. If that is the case, the item and its parent
are swapped. This operation is repeated until the entire heap again preserves
heap order. It may be repeated once for each level in the implicit tree, i.e.
at most $\lceil \log n \rceil$ times, and takes constant time in each iteration.

Deletions first remove the root item, located at \lstinline|items[1]|, and store
it as the eventual return value. The heap structure is then preserved by moving
the item at the tail of the array (\lstinline|items[n + 1]|) into the root position,
and then swapping it with its highest priority child until the item is again
in a position in which it is of higher priority than both children. Like insertions,
this operation takes constant effort in each iteration, and is repeated at most
once for each level, resulting in a worst case of $O(\log n)$.

Binary heaps are efficient in practice and conceptually simple as well as easy
to implement. They are space-efficient since they do not store any overhead per
item such as pointers (in \ac{BST}-based implementations). One of their main drawbacks
is that both deletes and inserts are of logarithmic complexity. Others
become apparent only in a concurrent setting, in which their tendency to
modify large parts of the data structure during both insertions and deletions
causes contention, high cache-coherence protocol traffic, and synchronization
issues.

\section{SkipList}

As previously discussed, \acp{BST} are a viable approach to implementing
priority queues with logarithmic worst-case bounds for insertions as well as
deletions. SkipLists \cite{pugh1990skip} are very similar conceptually,
but use a different approach to physically represent the data structure,
and use randomization in order to avoid having to perform regular maintenance
operations while preserving expected logarithmic time bounds.

\begin{figure}[ht]
\begin{lstlisting}
template <class K, class V>
class skiplist {
public:
    void insert(const K &key, const V &val);
    bool delete_min(V &val);

private:
    skiplist_node<K, V> *head[MAX_HEIGHT];
};

template <class K, class V>
struct skiplist_node {
    K key;
    V val;

    size_t level;
    skiplist_node<K, V> *next[MAX_HEIGHT];
};
\end{lstlisting}
\caption{A SkipList priority queue class.}
\label{fig:skiplist_members}
\end{figure}

A SkipList is essentially a linked list of specialized nodes, each of which
contains a key-value pair, an associated node level, and a list of pointers to
the next node (Figures \ref{fig:skiplist_members} and \ref{fig:skiplist_structure}).
The node's level determines how many pointers to the next node
exist, and a pointer at level $l$ links to the next node of level $\geq l$
within the data structure. Higher level pointers thus act as shortcuts into the
list, avoiding the usual linear cost search operation of linked lists.

\begin{figure}
\centering
    \begin{tikzpicture}[
        ->,
        start chain,
        every node/.style={font=\small},
        item/.style= box,
        label/.style={rectangle,minimum size = 5mm}
      ]

      \node[box] (3a) at (0, 15mm) {}; \node[box] (3h) at (70mm, 15mm) {};

      \node[box] (2a) at (0, 10mm) {}; \node[box] (2c) at (20mm, 10mm) {};
      \node[box] (2e) at (40mm, 10mm) {}; \node[box] (2h) at (70mm, 10mm) {};

      \node[box] (1a) at (0, 5mm) {}; \node[box] (1c) at (20mm, 5mm) {};
      \node[box] (1d) at (30mm, 5mm) {}; \node[box] (1e) at (40mm, 5mm) {}; \node[box] (1f) at (50mm, 5mm) {};
      \node[box] (1h) at (70mm, 5mm) {};

      \node[box] (0a) at (0, 0) {}; \node[box] (0b) at (10mm, 0) {0}; \node[box] (0c) at (20mm, 0) {1};
      \node[box] (0d) at (30mm, 0) {2}; \node[box] (0e) at (40mm, 0) {3}; \node[box] (0f) at (50mm, 0) {4};
      \node[box] (0g) at (60mm, 0) {5}; \node[box] (0h) at (70mm, 0) {};

      {
        [start chain] \chainin(0a); \chainin(0b) [join]; \chainin(0c) [join]; \chainin(0d) [join]; \chainin(0e) [join]; \chainin(0f) [join]; \chainin(0g) [join]; \chainin(0h) [join];
        [start chain] \chainin(1a); \chainin(1c) [join]; \chainin(1d) [join]; \chainin(1e) [join]; \chainin(1f) [join]; \chainin(1h) [join];
        [start chain] \chainin(2a); \chainin(2c) [join]; \chainin(2e) [join]; \chainin(2h) [join];
        [start chain] \chainin(3a); \chainin(3h) [join];
      }

      \draw[serif cm-serif cm] (-2.5mm,-5mm) -- node[below] {\texttt{head}} (2.5mm, -5mm);
      \draw[serif cm-serif cm] (7.5mm,-5mm) -- node[below] {Items} (62.5mm, -5mm);
      \draw[serif cm-serif cm] (67.5mm,-5mm) -- node[below] {\texttt{tail}} (72.5mm, -5mm);
    \end{tikzpicture}
\caption[A SkipList structure with 6 elements and a maximal level of 3.]
        {A SkipList with 6 elements and a maximal level of 3.
         Each column represents a single node. The first and last nodes are, respectively, artificial
         head and tail nodes.
         Note that the minimal element is always accessible through the first pointer on level 0.}
\label{fig:skiplist_structure}
\end{figure}

Insertions create a new node, assigning the level according to a geometric
distribution. The correct position for the new node is determined
by searching for the given key within the list.
Finally, the new node is physically
inserted by modifying pointers of previous nodes and the new node.

A search proceeds by starting
at the maximal level, and and repeatedly walking along its associated pointer list
until a node is found with a higher key than the desired one. The inspected level is
then decremented, and the operation is repeated (if $level > 0$), or the current
location returned as the correct position (otherwise).

\lstinline|delete_min| simply removes the head node of the list by setting its
successor at level 0 as the new head node, and then returns the previous head's value.

Note that since node levels are distributed geometrically, we expect each level $l$
to contain twice as many nodes as level $l + 1$. Thus both the expected maximal level
of all nodes, as well as the number of steps required to find any given key within
the SkipList is $O(\log n)$.

The SkipList has gained popularity in recent research into
parallel priority queues, since it does not require the frequent rebalancing
operations of \acp{BST}, and operations on nodes of different keys usually access
spacially disjoint parts of the data structure. In the context of concurrent
operations, both of these properties are very desirable: if several concurrent
insertions modify disjoint parts of the SkipList, contention is reduced.
And since the SkipList does not require balancing, both insertions and deletions
are simpler and more efficient to implement.

Unfortunately, and as we will see in our results in Chapter \ref{ch:evaluation}, SkipLists
have turned out to be rather slow in practice. This is most likely due to the fact
that each node is usually dynamically allocated in non-contiguous
parts of memory, resulting in very bad cache locality.
