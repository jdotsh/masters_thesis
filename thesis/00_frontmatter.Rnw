\begin{acknowledgements*}
To Martin and Jesper --- without your enthusiasm, ideas, and support, this thesis
would not have been possible.
\end{acknowledgements*}

\begin{kurzfassung}
Priority queues sind abstrakte Datenstrukturen welche eine Menge von Key/Value
Paaren speichern und effizienten Zugriff auf das minimale (maximale) Element
erlauben. Sie sind ein wichtiger Teil in vielen Bereichen der Informatik, wie zum Beispiel
Algorithmen (e.g., Dijkstra's k\"urzester Pfad Algorithmus) und Betriebssystemen
(e.g., Priority Schedulers).

Der aktuelle Trend hin zu Multiprozessor Systemen ben\"otigt neue
Implementationen von Basisdatenstrukturen, die auch bis auf viele Threads skalieren.
Sogenannte Lock-free Strukturen sind in der Hinsicht vielversprechend nachdem sie auf
blockierende Synchronisationsmechanismen verzichten.

An parallelen Priority queues ist im vergangenen Jahrzehnt intensiv geforscht worden.
In den letzten Jahren hatte sich die Forschung haupts\"achlich auf SkipList-basierte
Strukturen konzentriert, nachdem sie hervorragende disjoint-access Parallelismus
Eigenschaften vorweisen, i.e., Schreibzugriffe an verschiedenen Elementen betreffen
separate Teile der Datenstruktur. Contention zwischen verschiedenen Threads und
das Datenvolumen durch das Cache-coherency Protokoll kann daher reduziert reduziert werden.

Die Skalierbarkeit hat sich jedoch bisher nur begrenzt verbessert. Auf der einen Seite
haben strikte Priority queues einen inh\"arenten Engpass nachdem jede \lstinline|delete_min|
Operation auf das minimale (maximale) Element zugreift. Und auf der anderen
haben SkipLists wegen der dynamischen Allokation jeder Node relativ schlechte Cache Locality,
und daher eher niedrigen Throughput bei SkipList-basierten Designs.

Relaxed Datenstrukturen sind ein neuer und vielversprechender Zugang in dem h\"ohere Skalierbarkeit
durch schw\"achere Qualit\"atsgarantien erlangt wird. Die \klsm ist ein paralleler,
lock-free, und relaxed Priority queue Design, welcher hohe Skalierbarkeit verspricht:
1) einerseits durch die Benutzung von Arrays and der Merge Operation
f\"ur hohe Cache Locality, und 2) andererseits derart geschw\"achte semantische Garantien,
sodass \lstinline|delete_min| eines der $kP$ minimale (maximale) Elemente zur\"uckgeben
darf, wobei $P$ die Anzahl der Threads und $k$ ein Konfigurationsparameter ist.

\todo{Continue here.}
\end{kurzfassung}

\begin{abstract}
Priority queues are abstract data structures which store a set of key/value pairs
and allow efficient access to the item with the minimal (maximal) key. Such queues are an important
element in various areas of computer science such as algorithmics (e.g. Dijkstra's shortest
path algorithm) and operating system (e.g. priority schedulers).

The recent trend towards multiprocessor computing requires new implementations of basic
data structures which are able to be used concurrently and scale well to large numbers
of threads. Lock-free structures promise such scalability by avoiding
the use of blocking synchronization primitives.

Concurrent priority queues have been extensively researched over the past decades.
In recent years, most research within the field has focused on SkipList-based structures,
based mainly on the fact that they exhibit very high disjoint access parallelism, i.e.,
modifications on different elements access disjoint parts of the data structure.
Contention between threads and traffic through the cache-coherency protocol
can therefore be reduced.

However, so far scalability improvements have been very limited. On the one hand,
strict priority queues have an inherent sequential bottleneck since each \lstinline|delete_min|
operation attempts to access a single minimal (maximal) element. On the other,
SkipLists have less than optimal cache locality since each node is
usually allocated dynamically, which in turn results in fairly low throughput
for SkipList-based designs.

Relaxed data structures are a new and promising approach in which quality
guarantees are weakened in return for improved scalability.
The \klsm is a concurrent, lock-free, and relaxed priority queue design which
aims to improve scalability by 1) using arrays as backing data structures and the standard
merge algorithm as its central operation (for high cache locality); and 2) by relaxing
semantic guarantees to allow the \lstinline|delete_min| operation to return one
of the $kP$ minimal (maximal) elements, where $P$ is the number of threads and $k$ is a configuration parameter.

During the course of this thesis, we have implemented an improved standalone version of
the \klsm priority queue and explain its design and implementation in detail. We finally evaluate the
the \klsm against other state-of-the-art concurrent priority queues including
the Spraylist, the \citeauthor{linden2013skiplist} queue, and
\citeauthor{rihani2014multiqueues}'s Multiqueues.

In some benchmarking scenarios, including
the popular generic throughput benchmark, the \klsm priority queue shows exceptional scalability,
outperforming all other queues by up to a factor of ten; in others however,
its throughput drops dramatically. Out of the other designs, Multiqueues are the
clear winner, performing consistently across all benchmarks.
\end{abstract}
