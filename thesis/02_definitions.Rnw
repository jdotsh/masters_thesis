\chapter{Definitions} \label{ch:definitions}

This chapter introduces basic terms and concepts required in the remainder of the
thesis.

% Blocking, lock-free and wait-free data structures.
\section{Lock-freedom}

Concurrent data structures are intended to be accessed and updated simultaneously by several processes
at the same time. \emph{Lock-based} structures limit the  number of processes that may enter
a critical section at once through the use of locks.
\emph{Lock-free} data structures eschew the use of locks, and guarantee
that at least one process makes progress at all times. Since lock-free structures are
non-blocking, they are not susceptible to priority inversion (in which a high priority process is
prevented from running by a low priority process) and deadlock (two processes wait for a resource held by the other).
\emph{Wait-freedom} further guarantees that every process finishes each operation in a bounded number of steps.
In practice, wait-freedom often introduces an unacceptable overhead; lock-freedom
however has turned out to be both efficient and to scale well to large numbers of processes.
Recently, \citeauthor{kogan2012methodology} have developed a methodology for implementing efficient
wait-free data structures from lock-free cases \cite{kogan2012methodology}, but it is neither trivial
to implement, nor is it clear whether performance improvements apply to all types of data structures.

% Linearizability, sequential and quiescent consistency.
\section{Correctness Conditions}

\begin{figure}
\begin{minipage}[b]{\textwidth}
    \centering
    \begin{tikzpicture}[start chain,
        ->,
        every node/.style={font = \small},
        label/.style={rectangle,minimum size = 5mm}
      ]

        \begin{scope}[start chain = 1 going right]
            \node [on chain=1] (t1_start) {Thread A};
            \node [on chain=1, xshift = 90mm] (t1_end) {};
        \end{scope}

        \begin{scope}[start chain = 2 going right]
            \node [on chain=2, below = of t1_start, yshift = 7.5mm] (t2_start) {Thread B};
            \node [on chain=2, xshift = 90mm] (t2_end) {};
        \end{scope}

        \path[dashed, -stealth'] (t1_start) edge node [above] {} (t1_end);
        \path[dashed, -stealth'] (t2_start) edge node [above] {} (t2_end);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t2_start.east) + (10mm, 0)$) edge node [above] {\lstinline|insert(5)|}
            ($(t2_start.east) + (30mm, 0)$)
            ($(t2_start.east) + (40mm, 0)$) edge node [above] {\lstinline|delete_min(1)|}
            ($(t2_start.east) + (60mm, 0)$);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t1_start.east) + (70mm, 0)$) edge node [above] {\lstinline|insert(1)|}
            ($(t1_start.east) + (90mm, 0)$);
    \end{tikzpicture}
    \subcaption{Sequentially consistent, but neither quiescently consistent nor linearizable.}
\end{minipage}
\begin{minipage}[b]{\textwidth}
    \centering
    \begin{tikzpicture}[start chain,
        ->,
        every node/.style={font = \small},
        label/.style={rectangle,minimum size = 5mm}
      ]

        \begin{scope}[start chain = 1 going right]
            \node [on chain=1] (t1_start) {Thread A};
            \node [on chain=1, xshift = 90mm] (t1_end) {};
        \end{scope}

        \begin{scope}[start chain = 2 going right]
            \node [on chain=2, below = of t1_start, yshift = 7.5mm] (t2_start) {Thread B};
            \node [on chain=2, xshift = 90mm] (t2_end) {};
        \end{scope}

        \path[dashed, -stealth'] (t1_start) edge node [above] {} (t1_end);
        \path[dashed, -stealth'] (t2_start) edge node [above] {} (t2_end);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t2_start.east) + (10mm, 0)$) edge node [above] {\lstinline|delete_min(5)|}
            ($(t2_start.east) + (30mm, 0)$)
            ($(t2_start.east) + (40mm, 0)$) edge node [above] {\lstinline|insert(5)|}
            ($(t2_start.east) + (60mm, 0)$);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t1_start.east) + (25mm, 0)$) edge node [above] {\lstinline|insert(1)|}
            ($(t1_start.east) + (45mm, 0)$);
    \end{tikzpicture}
    \subcaption{Quiescently consistent, but neither sequentially consistent nor linearizable.}
    \label{fig:correctness_criteria_b}
\end{minipage}
\begin{minipage}[b]{\textwidth}
    \centering
    \begin{tikzpicture}[start chain,
        ->,
        every node/.style={font = \small},
        label/.style={rectangle,minimum size = 5mm}
      ]

        \begin{scope}[start chain = 1 going right]
            \node [on chain=1] (t1_start) {Thread A};
            \node [on chain=1, xshift = 90mm] (t1_end) {};
        \end{scope}

        \begin{scope}[start chain = 2 going right]
            \node [on chain=2, below = of t1_start, yshift = 7.5mm] (t2_start) {Thread B};
            \node [on chain=2, xshift = 90mm] (t2_end) {};
        \end{scope}

        \path[dashed, -stealth'] (t1_start) edge node [above] {} (t1_end);
        \path[dashed, -stealth'] (t2_start) edge node [above] {} (t2_end);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t2_start.east) + (10mm, 0)$) edge node [above] {\lstinline|insert(5)|}
            ($(t2_start.east) + (30mm, 0)$)
            ($(t2_start.east) + (40mm, 0)$) edge node [above] {\lstinline|delete_min(1)|}
            ($(t2_start.east) + (60mm, 0)$);

        \path[line width = 1mm, serif cm-serif cm, every node/.style= { font = \footnotesize }]
            ($(t1_start.east) + (50mm, 0)$) edge node [above] {\lstinline|insert(1)|}
            ($(t1_start.east) + (70mm, 0)$);
    \end{tikzpicture}
    \subcaption{Sequentially consistent, quiescently consistent and linearizable.}
    \label{fig:correctness_criteria_c}
\end{minipage}
\caption{A history of concurrent operations on an initially empty min-priority queue.}
\label{fig:correctness_criteria}
\end{figure}

There are several different criteria which allow reasoning about the correctness of concurrent
data structures. \emph{Linearizable} \cite{herlihy1990linearizability} operations appear to take
effect at a single instant in time between the operation invocation and response at so-called linearization points.
A sequence of concurrent linearizable operations must have an equivalent effect to some legal sequential sequence of
the same operations.
\emph{Quiescently consistent} \cite{shavit1996diffracting} data structures
guarantee that the result of a set of parallel operations is equal to the result of a sequential ordering
after a period of quiescence, i.e. an interval without active operations, has passed; however,
no guarantees are given while one or more operations are in progress.
Linearizability as well as quiescent consistency are composable ---
any data structure composed of linearizable (quiescently consistent) objects is also linearizable
(quiescently consistent).
\emph{Sequential consistency} \cite{lamport1979make} requires the result of a set of operations
executed in parallel to be equivalent to the result of some sequential ordering of the same
operations. Contrary to linearizability and quiescent consistency, sequential consistency is
neither composable nor a realtime condition (i.e., the realtime order of operations may not be equivalent to some
sequential execution with the same effect).

Sequential and quiescent consistency are incomparable; a history may be sequentially consistent
without being quiescently consistent and vice versa. Linearizability on the other hand
implies both sequential and quiescent consistency.

Figure \ref{fig:correctness_criteria} shows three examples of thread histories. The
first is sequentially consistent since intra-thread reordering (delaying Thread B
such that key 1 is inserted before it is deleted) results in a valid
sequential history. It is is neither quiescently consistent (no valid history
exists during the period of quiescence after \lstinline|delete_min|), nor
linearizable (there are no linearization points resulting in a valid history).
The second in Figure \ref{fig:correctness_criteria_b} is quiescently consistent,
but can neither be linearized, nor is it sequentially consistent.
Example \ref{fig:correctness_criteria_c} on the other hand is sequentially consistent,
quiescently consistent, and linearizable (if \lstinline|delete_min| has its
linearization point after that of \lstinline|insert(1)|).

% Relaxed consistency definitions.
\section{Relaxation}

In recent years, weaker versions of these criteria have been investigated as
promising approaches towards higher scalability. Correctness criteria such as
linearizability are usually applied to all operations and all threads (so-called
\emph{global ordering semantics}). On the other hand, in \emph{local ordering semantics},
threads maintain thread-local copies of a central data structure, and modification
to distinct local copies are not linearized between threads.

\begin{figure}
\footnotesize
\begin{minipage}[b]{0.33\textwidth}
\centering
\begin{tikzpicture}[start chain=going right,
	node distance=0pt]

\node[box] at (0, 0) {$A$};
\node[box] at (0, 5mm) {$B$};
\node[box] at (0, 10mm) {$C$};

\path[serif cm-serif cm] (5mm, 12.5mm) edge node [sloped, above] {$\rho_t$} (5mm, 2.5mm);
\path[serif cm-serif cm] (-5mm,2.5mm) edge node[sloped, above] {$\rho_s$} (-5mm, 12.5mm);
\end{tikzpicture}
\subcaption{The initial stack.}
\end{minipage}%
\begin{minipage}[b]{0.33\textwidth}
\centering
\begin{tikzpicture}[start chain=going right,
	node distance=0pt]

\node[box] at (0, 0) {$A$};
\node[box] at (0, 5mm) {$B$};
\node[box] at (0, 10mm) {$C$};
\node[box] at (0, 15mm) {$D$};

\path[serif cm-serif cm] (5mm,17.5mm) edge node[sloped, above] {$\rho_t$} (5mm, 7.5mm);
\path[serif cm-serif cm] (-5mm,7.5mm) edge node[sloped, above] {$\rho_s$} (-5mm, 17.5mm);
\end{tikzpicture}
\subcaption{\lstinline|push(D)|}
\end{minipage}%
\begin{minipage}[b]{0.33\textwidth}
\centering
\begin{tikzpicture}[start chain=going right,
	node distance=0pt]

\node[box] at (0, 0) {$A$};
\node[box] at (0, 5mm) {$B$};
\node[deleted_box] at (0, 10mm) {$C$};
\node[box] at (0, 15mm) {$D$};

\path[serif cm-serif cm] (5mm,17.5mm) edge node[sloped, above] {$\rho_t$} (5mm, 7.5mm);
\path[serif cm-serif cm] (-5mm,2.5mm) edge node[sloped, above] {$\rho_s$} (-5mm, 17.5mm);
\end{tikzpicture}
\subcaption{\lstinline|pop(C)|}
\end{minipage}
\caption{Temporal vs. structural $\rho$ relaxation on a stack for $\rho=2$. The items that can be relaxed by structural $\rho$-relaxation are marked with $\rho_s$, by temporal with $\rho_t$. After the pop, temporal $\rho$-relaxation is not allowed to skip $B$, since two items were added to the stack after $B$, even though $C$ was deleted in the meantime.}
\label{fig:temp_vs_struct_rho}
\end{figure}

\emph{Quasi-linearizability} \cite{afek2010quasi}, proposed in \citeyear{afek2010quasi},
was possibly the first relaxed correctness condition and sets a fixed upper bound to the 
distance to a valid sequential operation sequence. 
Distance is a concept founded on the comparison of a concurrent history (a sequence of method invocation and completion events) against
its sequential pendant; the distance of a method invocation is, roughly, the difference of its position within both histories.
\citeauthor{afek2010quasi} give an example in which a stack history is allowed to skip up to $k$
\lstinline|enqueue| operations and an infinite number of \lstinline|dequeue| operations.

\emph{Quantitative relaxation}
\cite{henzinger2013quantitative} is a closely related concept to quasi-linearizability. However,
unlike quasi-linearizability which is based on synax, quantitative relaxation is based
on the semantics of a data structure, e.g., allowing a priority queue to return
the $k$-smallest item. 

\emph{$\rho$-relaxation} \cite{wimmer2013data,wimmerphd}
is similar to quantitative relaxation, and defines correctness guarantees in terms
of how many items may be skipped, or ignored, by an operation. \citeauthor{wimmerphd}
further distinguishes between temporal $\rho$-relaxation, based on the recency of items,
and structural $\rho$-relaxation, which relies on the position of an item within
the data structure (see Figure \ref{fig:temp_vs_struct_rho}). 

\emph{Local linearizability} \cite{haas2015local} is a recent guarantee that simply requires each thread-induced history
(containing only operations on items inserted by that thread) to be linearizable.
Note that local linearizability provides only weak guarantees; for instance, consider a concurrent priority
queue consisting of thread-local queues protected by a lock, in which all insertions are local
and deletions take items from a random thread's queue. This queue is locally linearizable, even though
it cannot provide any global guarantees as to the quality of its returned items. In the worst case,
it may even continually return the largest item within the entire priority queue.

% Synchronization primitives.
\section{Synchronization Primitives}

Lock-free algorithms and data structures are commonly constructed using synchronization primitives
such as \acf{CAS}, \ac{FAA}, \ac{FAO}, and \ac{TAS}. The \ac{CAS} instruction, which atomically
compares a memory location to an expected value and sets it to a new value if they are equal,
is implemented on most modern architectures and can be considered a basic building block of lock-free
programming since it is the most powerful of these operations \cite{herlihy1991wait}.
More exotic primitives such as \ac{DCAS} and \ac{DCSS} exist as well, but are not yet
widely available in hardware and require software emulations (with associated overhead)
to be used \cite{harris2002practical}.

\section{Hardware Topologies}

Multiprocessor machines (Figure \ref{fig:system_topology})
are often built by combining several physical processors (often called sockets), each containing a collection
of processing cores (and their associated cache hierarchy), which themselves may contain
one or more processing units each. Every processing unit is capable of running
one independent hardware thread.

\begin{figure}
\centering
    \begin{tikzpicture}[start chain,
        ->,
        every node/.style={font = \small},
        label/.style={rectangle,minimum size = 5mm}
      ]

        \begin{scope}[start chain = 1 going right]
            \node [on chain=1] (m) {Machine};
            \node [on chain=1] (p) {Processor};
            \node [on chain=1] (pc) {Processing Core};
            \node [on chain=1] (pu) {Processing Unit};
        \end{scope}

        \begin{scope}[start chain = 2 going right]
            \node [on chain=2, above = of m] (ram) {RAM};
            \node [on chain=2, above = of p] (l3) {L3 Cache};
            \node [on chain=2, above = of pc] (l21) {L1, L2 Caches};
        \end{scope}

        \path[->, every node/.style= { font = \footnotesize }]
            (m) edge node [above] {contains} (p)
            (p) edge node [above] {contains} (pc)
            (pc) edge node [above] {contains} (pu);

        \path[<->, every node/.style= { font = \footnotesize }]
            (ram) edge node [above] {} (m)
            (l3) edge node [above] {} (p)
            (l21) edge node [above] {} (pc);

        \path[->, every node/.style= { font = \footnotesize }]
            (l21) edge node [above] {accesses} (l3)
            (l3) edge node [above] {accesses} (ram);
    \end{tikzpicture}
\caption{A typical system topology.}
\label{fig:system_topology}
\end{figure}

Shared memory multiprocessor machines usually have a so-called \ac{NUMA} architecture,
in which the cost of memory accesses is determined by both the physical location
of the memory and the active processing core. Often, each processing core
has one or more dedicated levels of memory cache (typically L1 and L2 caches),
and a level of shared cache per processor (typically L3). Access time to these
cache levels rises by about an order of magnitude with each level; L1 caches
being the fastest, followed by accesses to L2 and L3 caches, \ac{RAM}, and finally
the hard disk. Many concurrent algorithms are only efficient as long as all participating
threads are located on a single processor and share an L3 cache.

Cache coherency is a problem which arises in programs executed concurrently
whenever multiple threads have the same memory location (variable)
cached in their local caches. Whenever a thread updates the variable, other threads'
caches must be notified that the variable has changed, and its value must be
updated if required. This type of traffic is guided by the \emph{cache coherency protocol}.

Locality is another critical aspect of effective cache use. Cache contents are
loaded by blocks containing not just the requested location, but also its neighborhood.
Thus algorithms with sequential data access patterns incur fewer cache loads than those
with random accesses, adding up to significant performance gains.

An area in memory accessed frequently by a large number of processes is said to be \emph{contended}.
Contention is a limiting factor for scalability: concurrent reads and writes to the same
location must be serialized by the cache coherence protocol, and only a single concurrent \ac{CAS}
can succeed while all others must retry. \emph{Disjoint-access parallelism} is the concept of
spreading such accesses in order to reduce contention as much as possible.

\section{C++11 Memory Model}

While thread support has previously only been available for the C++ language through the
\ac{pthreads} library (and others) \cite{boehm2005threads},
the C++11 standard now specifies a fully multi-threaded abstract state machine with a
clearly defined memory model. A memory model restricts the order in which changes to memory locations by one
thread can become visible to other threads; for instance, usage of the the \lstinline|std::atomic|
type together with its \lstinline|load()| and \lstinline|store()| operations ensures
portable multithreaded behavior across different architectures. It is possible to vary
the strictness of provided guarantees between sequential consistency (on the strict end)
and relaxed behavior (guaranteeing only atomicity).

In our implementation, we extensively use the previously mentioned \lstinline|std::atomic| type
together with its \lstinline|load|, \lstinline|store|, \lstinline|fetch_add|, and 
\lstinline|compare_exchange_strong| operations. When possible, we explicitly use 
relaxed memory ordering (\lstinline|std::memory_order_relaxed|) as it is the most
efficient (and weakest) of all memory ordering types, requiring only atomicity.
