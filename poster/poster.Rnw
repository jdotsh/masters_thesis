\documentclass[final,hyperref={pdfpagelabels=true}]{beamer}

\usepackage{TUINFPST}

\usepackage{acronym}
\usepackage[backend=bibtex,sortcites=true]{biblatex}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{xspace}

\newcommand{\klsm}{$k$-LSM\xspace}

\title[Software Engineering \& Internet Computing]{
  \klsm: A Relaxed Lock-Free Priority Queue
}
\author[gruber@par.tuwien.ac.at]{Jakob Gruber}
\institute[]{%
  Technische Universit{\"a}t Wien\\[0.25\baselineskip]
  Institut f{\"u}r Informationssysteme\\[0.25\baselineskip]
  Arbeitsbereich: Parallel Computing\\[0.25\baselineskip]
  Betreuer: Prof. Dr. Scient. Jesper Larsson Tr\"aff
}
\titlegraphic{\includegraphics[height=52mm]{parcomp_logo}}
\date[\today]{\today}
\subject{epilog}
\keywords{concurrency, algorithms, lock-free, relaxed, priority queue}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setbeamercolor{block body}{fg=black,bg=white}
\setbeamercolor{block title}{fg=white,bg=TuWienBlue}

\setbeamertemplate{block begin}{
  \begin{beamercolorbox}{block title}%
    \begin{tikzpicture}%
      \node[draw,rectangle,line width=3pt,rounded corners=0pt,inner sep=0pt]{%
        \begin{minipage}[c][2cm]{\linewidth}
          \centering\textbf{\insertblocktitle}
        \end{minipage}
      };
    \end{tikzpicture}%
  \end{beamercolorbox}
  \vspace*{1cm}
  \begin{beamercolorbox}{block body}%
}

\setbeamertemplate{block end}{
  \end{beamercolorbox}
  \vspace{2cm}
}

% for crop marks, uncomment the following line
\usepackage[cross,width=88truecm,height=123truecm,center]{crop}

\input{acronyms}
\bibliography{bibliography.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{frame}
\begin{columns}[t]
% ---------------------------------------------------------%
\begin{column}{.45\textwidth}
\begin{block}{Context}
\begin{itemize}
\justifying
\item \emph{Priority queues} are abstract data structures which store a set of key/value pairs
and allow efficient access to the item with the minimal (maximal) key.

\item \emph{Concurrency}. Due to the recent trend towards multiprocessor computing, it is becoming ever
more vital to develop data structure designs that scale well to a large number
of threads.

\item \emph{Challenges}.
However, priority queues with traditional semantics incur an inherent sequential
bottleneck since each concurrent deletion attempts to remove the same item,
resulting in high contention at the minimal (maximal) item.

\item \emph{The traditional approach}. While some gains can be made by optimizing access to the minimal (maximal)
element, results have shown limited scalability.

\item \emph{Relaxation}. However, recently another promising approach based on weakening of
semantic guarantees has been gaining in popularity. Contrary to traditional,
strict priority queues, relaxed priority queues allow deletions to
return one of several potential candidate items, thus eliminating the
bottleneck at the minimal (maximal) item.

\item The \emph{\klsm} is a relaxed priority queue design offering strong and
parameterizable quality guarantees, and is both highly performant as well
as scalable to a large number of threads. We present a standalone implementation
of the \klsm and evaluate its throughput and quality against other state of the art
priority queues.
% TODO: Possible duplicate statement.
\end{itemize}
\end{block}

\begin{block}{The \klsm}
\justifying
The \emph{\klsm} is a relaxed, linearizable and lock-free priority queue design by
\citeauthor{wimmer2015lock} \cite{wimmer2015lock}, composed of two independent but
complementary priority queues: the \ac{SLSM}, a centralized queue with strong
guarantees but limited performance; and the \ac{DLSM}, a distributed design without
global guarantees but having very high performance. The \klsm is:
\begin{itemize}
\justifying
\item \emph{Linearizable}: Each operation appears to take effect at some instant
in time.

\item \emph{Lock-free}: At least one process makes progress at all times.

\item \emph{Relaxed}: Deletions may return one of the $kP$ minimal items, where
$k$ is a configuration parameter and $P$ is the number of threads.

\item \emph{Cache-efficient}: Usage of arrays and the standard merge algorithm
result in good cache locality properties and high performance.
\end{itemize}

Previously only available as part of the task-scheduling framework \emph{Pheet}
(\url{www.pheet.org}), we have implemented an efficient standalone version
of the \klsm. Our implementation is:
\begin{itemize}
\justifying
\item \emph{Scalable}: Under ideal circumstances and with sufficient
relaxation, the \klsm scales until the maximal thread-count on all tested
machines.

\item \emph{Performant}: The \klsm outperforms the best other concurrent
priority queues by up to a factor of ten.
\end{itemize}
\end{block}
\end{column}
% ---------------------------------------------------------%

% ---------------------------------------------------------%
\begin{column}{.45\textwidth}

\begin{block}{Results}
\begin{itemize}
\justifying
\item \emph{Algorithms}. The \klsm was evaluated against other state of the art designs, including
the SprayList \cite{alistarhspraylist} (relaxed, lock-free, SkipList-based, probabilistic guarantees), the
\citeauthor{linden2013skiplist} queue \cite{linden2013skiplist} (strict, lock-free, SkipList-based), and
the Multiqueues \cite{rihani2014multiqueues} (relaxed, lock-based, no guarantees).

\item \emph{Benchmarks}. Throughput benchmarks measure the millions of operations per second.

\vspace{1cm}

<<echo = FALSE>>=
\SweaveInput{pqplot.Rnw}
@

\begin{figure}[ht]
\begin{center}
<<fig = TRUE, width = 10, echo = FALSE>>=
pqplot("results/20151112_mars_uni_uni")
@
\end{center}
\caption{Uniform workload, uniform key generation.}
\label{fig:mars_uni_uni}
\end{figure}

In addition to the standard benchmark (equal mixture of operations on each thread,
uniform key generation), we experimented with split workloads (threads are either
dedicated inserters or deleters) and ascending/descending key generation.

The \klsm demonstrates exceptional performance under the standard uniform/uniform
benchmark.
Unfortunately, the \klsm is less successful under split workloads and ascending
key generation, since both place more stress on the centralized \ac{SLSM} component.

We also present the first evaluation of result quality, demonstrating that
on average, the \klsm's results are within the best $5\%$ of their guaranteed
range.

\end{itemize}

\end{block}

\begin{block}{References}
\printbibliography
\end{block}
\end{column}
% ---------------------------------------------------------%
\end{columns}

\end{frame}
\end{document}
